{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "333938ac-4984-49d6-a244-c1b9f9565676",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar bibliotecas necesarias\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "169a6389-82e1-45d8-8c8f-e8175f98b534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ID  LIMIT_BAL  SEX  EDUCATION  MARRIAGE  AGE  PAY_0  PAY_2  PAY_3  PAY_4  \\\n",
      "0   1      20000    2          2         1   24      2      2     -1     -1   \n",
      "1   2     120000    2          2         2   26     -1      2      0      0   \n",
      "2   3      90000    2          2         2   34      0      0      0      0   \n",
      "3   4      50000    2          2         1   37      0      0      0      0   \n",
      "4   5      50000    1          2         1   57     -1      0     -1      0   \n",
      "\n",
      "   ...  BILL_AMT4  BILL_AMT5  BILL_AMT6  PAY_AMT1  PAY_AMT2  PAY_AMT3  \\\n",
      "0  ...          0          0          0         0       689         0   \n",
      "1  ...       3272       3455       3261         0      1000      1000   \n",
      "2  ...      14331      14948      15549      1518      1500      1000   \n",
      "3  ...      28314      28959      29547      2000      2019      1200   \n",
      "4  ...      20940      19146      19131      2000     36681     10000   \n",
      "\n",
      "   PAY_AMT4  PAY_AMT5  PAY_AMT6  default payment next month  \n",
      "0         0         0         0                           1  \n",
      "1      1000         0      2000                           1  \n",
      "2      1000      1000      5000                           0  \n",
      "3      1100      1069      1000                           0  \n",
      "4      9000       689       679                           0  \n",
      "\n",
      "[5 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "# Leer el dataset, configurando la segunda fila como encabezado\n",
    "df = pd.read_csv('dataset.csv', header=1)\n",
    "\n",
    "# Ver las primeras filas para asegurarse de que todo está en orden\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f284ab1b-267c-42a4-bb9a-1f2d28ceef65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separar las características y la variable objetivo\n",
    "X = df.iloc[:, 1:-1]\n",
    "y = df.iloc[:, -1]\n",
    "\n",
    "# Estandarizar las características\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "259f23dc-8f01-49f2-9962-d0a3f6878ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir los datos en conjuntos de entrenamiento, validación y prueba\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a16b540-38bd-4bb9-8bf7-54202a57b889",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier(hidden_layer_sizes=(5, 3, 1), max_iter=15000, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(hidden_layer_sizes=(5, 3, 1), max_iter=15000, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MLPClassifier(hidden_layer_sizes=(5, 3, 1), max_iter=15000, random_state=42)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Crear una red neuronal\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(5,3,1), max_iter=15000, random_state=42)\n",
    "\n",
    "# Entrenar la red neuronal\n",
    "mlp.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "123764ec-1594-42d7-a0ad-76cef547413b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión en el conjunto de validación: 0.82\n"
     ]
    }
   ],
   "source": [
    "# Realizar predicciones en el conjunto de validación\n",
    "y_val_pred = mlp.predict(X_val)\n",
    "\n",
    "# Calcular la precisión\n",
    "accuracy = accuracy_score(y_val, y_val_pred)\n",
    "print(f'Precisión en el conjunto de validación: {accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa3e1f5c-8a54-437f-9bf6-ce3d457c2fd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión en el conjunto de prueba: 0.82\n"
     ]
    }
   ],
   "source": [
    "# Realizar predicciones en el conjunto de prueba\n",
    "y_test_pred = mlp.predict(X_test)\n",
    "\n",
    "# Calcular la precisión\n",
    "accuracy_test = accuracy_score(y_test, y_test_pred)\n",
    "print(f'Precisión en el conjunto de prueba: {accuracy_test:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e1a33ec-bd5e-4d25-a7e5-36effc267014",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "188c545d-b14b-4a06-aa32-0f88bb7a5a78",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>X10</th>\n",
       "      <th>...</th>\n",
       "      <th>X15</th>\n",
       "      <th>X16</th>\n",
       "      <th>X17</th>\n",
       "      <th>X18</th>\n",
       "      <th>X19</th>\n",
       "      <th>X20</th>\n",
       "      <th>X21</th>\n",
       "      <th>X22</th>\n",
       "      <th>X23</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>689</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>120000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3272</td>\n",
       "      <td>3455</td>\n",
       "      <td>3261</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>90000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>14331</td>\n",
       "      <td>14948</td>\n",
       "      <td>15549</td>\n",
       "      <td>1518</td>\n",
       "      <td>1500</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>28314</td>\n",
       "      <td>28959</td>\n",
       "      <td>29547</td>\n",
       "      <td>2000</td>\n",
       "      <td>2019</td>\n",
       "      <td>1200</td>\n",
       "      <td>1100</td>\n",
       "      <td>1069</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>50000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>20940</td>\n",
       "      <td>19146</td>\n",
       "      <td>19131</td>\n",
       "      <td>2000</td>\n",
       "      <td>36681</td>\n",
       "      <td>10000</td>\n",
       "      <td>9000</td>\n",
       "      <td>689</td>\n",
       "      <td>679</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       X1 X2 X3 X4  X5  X6 X7  X8  X9 X10  ...    X15    X16    X17   X18  \\\n",
       "1   20000  2  2  1  24   2  2  -1  -1  -2  ...      0      0      0     0   \n",
       "2  120000  2  2  2  26  -1  2   0   0   0  ...   3272   3455   3261     0   \n",
       "3   90000  2  2  2  34   0  0   0   0   0  ...  14331  14948  15549  1518   \n",
       "4   50000  2  2  1  37   0  0   0   0   0  ...  28314  28959  29547  2000   \n",
       "5   50000  1  2  1  57  -1  0  -1   0   0  ...  20940  19146  19131  2000   \n",
       "\n",
       "     X19    X20   X21   X22   X23  Y  \n",
       "1    689      0     0     0     0  1  \n",
       "2   1000   1000  1000     0  2000  1  \n",
       "3   1500   1000  1000  1000  5000  0  \n",
       "4   2019   1200  1100  1069  1000  0  \n",
       "5  36681  10000  9000   689   679  0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cargar los datos desde un archivo CSV\n",
    "df = pd.read_csv('dataset.csv')\n",
    "\n",
    "# Eliminar la primera columna que parece ser un índice\n",
    "df = df.drop(df.columns[0], axis=1)\n",
    "df = df.iloc[1:]\n",
    "\n",
    "# Mostrar las primeras 5 filas del DataFrame para una rápida inspección\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7c57f5ec-2b36-4c0f-868c-3e85a8eb57df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['X1', 'X2', 'X3', 'X4', 'X5', 'X6', 'X7', 'X8', 'X9', 'X10', 'X11',\n",
      "       'X12', 'X13', 'X14', 'X15', 'X16', 'X17', 'X18', 'X19', 'X20', 'X21',\n",
      "       'X22', 'X23', 'Y'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ff68877-df9f-4335-9b66-240ddd591a8e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y      1.000000\n",
      "X6     0.324794\n",
      "X7     0.263551\n",
      "X8     0.235253\n",
      "X9     0.216614\n",
      "X10    0.204149\n",
      "X11    0.186866\n",
      "X3     0.028006\n",
      "X5     0.013890\n",
      "X17   -0.005372\n",
      "X16   -0.006760\n",
      "X15   -0.010156\n",
      "X14   -0.014076\n",
      "X13   -0.014193\n",
      "X12   -0.019644\n",
      "X4    -0.024339\n",
      "X2    -0.039961\n",
      "X23   -0.053183\n",
      "X22   -0.055124\n",
      "X20   -0.056250\n",
      "X21   -0.056827\n",
      "X19   -0.058579\n",
      "X18   -0.072929\n",
      "X1    -0.153520\n",
      "Name: Y, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Cell 8: Compute the correlation matrix\n",
    "correlation_matrix = df.corr()\n",
    "print(correlation_matrix['Y'].sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f45144cd-cab6-44b0-8015-731664063f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 11: Drop features with low correlation\n",
    "#low_corr_features = ['X2', 'X4', 'X12', 'X13', 'X14', 'X15', 'X16', 'X17']\n",
    "#X = X.drop(low_corr_features, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "22b7394d-ba13-4064-9d17-da4b6c4213ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separar las variables independientes (X) y la variable dependiente (y)\n",
    "X = df.drop('Y', axis=1)\n",
    "y = df['Y']\n",
    "\n",
    "# Escalar las características\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a669f7eb-33f7-4f76-ad06-c7bd9705614f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir los datos\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "49453457-72b8-4f40-bbc7-8f7dac001a4a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.55890707  0.81016074 -1.0794572  -1.05729503  0.48976158 -1.76484282\n",
      "  -1.55887596 -1.53219171 -1.52194355 -1.53004603 -1.48604076 -0.69564183\n",
      "  -0.69098343 -0.67792868 -0.67249727 -0.66305853 -0.65272422 -0.34194162\n",
      "  -0.25698952 -0.29680127 -0.30806256 -0.31413612 -0.29338206]\n",
      " [-0.90549825  0.81016074 -1.0794572   0.85855728 -1.35450619 -0.87499115\n",
      "  -0.72356993 -0.69666346 -0.66659873 -0.64756476 -0.61645169 -0.64906049\n",
      "  -0.65616665 -0.64477715 -0.59788407 -0.50169961 -0.64164167 -0.18810479\n",
      "  -0.1562538  -0.02417729  0.31813835 -0.27093689 -0.12575132]\n",
      " [-0.90549825  0.81016074  0.18582826 -1.05729503  0.05581622  1.79456386\n",
      "   1.78234817  1.8099213   1.89943574  0.23491652  0.25313738 -0.06817894\n",
      "  -0.05648348  0.03045276  0.07295074  0.05373037 -0.06289781 -0.34194162\n",
      "  -0.05300077 -0.29680127 -0.1801414  -0.08504931 -0.29338206]\n",
      " [ 0.25061122  0.81016074  1.45111372 -1.05729503  2.00857033  5.35397055\n",
      "   4.28826627  3.4809778   2.75478056  1.99987907  1.99231551  0.80073284\n",
      "   0.82174796  0.83164118  0.92156703  1.00481045 -0.65272422 -0.34194162\n",
      "  -0.25698952 -0.29680127 -0.30806256 -0.31413612 -0.29338206]\n",
      " [ 0.55890707 -1.23432296 -1.0794572  -1.05729503 -0.05267012 -0.87499115\n",
      "  -0.72356993 -0.69666346  0.18874609 -0.64756476 -0.61645169 -0.66815476\n",
      "  -0.66278437 -0.36371735 -0.40665667 -0.44319261 -0.27224034 -0.22016419\n",
      "   0.68990889 -0.23318901  0.54946884  1.17636813  0.99028686]]\n",
      "28466    1.0\n",
      "27623    0.0\n",
      "28377    0.0\n",
      "10918    0.0\n",
      "27235    0.0\n",
      "Name: Y, dtype: float64\n",
      "float64\n",
      "float64\n",
      "float64\n",
      "float64\n"
     ]
    }
   ],
   "source": [
    "y_train = y_train.astype(float)\n",
    "y_val = y_val.astype(float)\n",
    "y_test = y_test.astype('float')\n",
    "\n",
    "print(X_train[:5])\n",
    "print(y_train[:5])\n",
    "print(X_train.dtype)\n",
    "print(y_train.dtype)\n",
    "print(X_test.dtype)\n",
    "print(y_test.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5c022629-e26b-4c10-af4d-ecd68fbd7386",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear el modelo\n",
    "model = Sequential()\n",
    "model.add(Dense(64, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compilar el modelo\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e9c875b3-8a56-41e1-8eaa-4ee899fb4abb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "657/657 [==============================] - 2s 2ms/step - loss: 0.4857 - accuracy: 0.8001 - val_loss: 0.4526 - val_accuracy: 0.8142\n",
      "Epoch 2/50\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.4549 - accuracy: 0.8130 - val_loss: 0.4474 - val_accuracy: 0.8160\n",
      "Epoch 3/50\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.4440 - accuracy: 0.8150 - val_loss: 0.4441 - val_accuracy: 0.8156\n",
      "Epoch 4/50\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.4409 - accuracy: 0.8169 - val_loss: 0.4453 - val_accuracy: 0.8162\n",
      "Epoch 5/50\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.4364 - accuracy: 0.8192 - val_loss: 0.4419 - val_accuracy: 0.8147\n",
      "Epoch 6/50\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.4366 - accuracy: 0.8210 - val_loss: 0.4485 - val_accuracy: 0.8149\n",
      "Epoch 7/50\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.4340 - accuracy: 0.8198 - val_loss: 0.4418 - val_accuracy: 0.8144\n",
      "Epoch 8/50\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.4313 - accuracy: 0.8214 - val_loss: 0.4418 - val_accuracy: 0.8182\n",
      "Epoch 9/50\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.4316 - accuracy: 0.8200 - val_loss: 0.4421 - val_accuracy: 0.8164\n",
      "Epoch 10/50\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.4293 - accuracy: 0.8202 - val_loss: 0.4432 - val_accuracy: 0.8171\n",
      "Epoch 11/50\n",
      "657/657 [==============================] - 2s 2ms/step - loss: 0.4301 - accuracy: 0.8214 - val_loss: 0.4420 - val_accuracy: 0.8138\n",
      "Epoch 12/50\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.4293 - accuracy: 0.8205 - val_loss: 0.4436 - val_accuracy: 0.8122\n",
      "Epoch 13/50\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.4292 - accuracy: 0.8216 - val_loss: 0.4449 - val_accuracy: 0.8142\n",
      "Epoch 14/50\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.4270 - accuracy: 0.8221 - val_loss: 0.4451 - val_accuracy: 0.8156\n",
      "Epoch 15/50\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.4266 - accuracy: 0.8211 - val_loss: 0.4444 - val_accuracy: 0.8169\n",
      "Epoch 16/50\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.4260 - accuracy: 0.8225 - val_loss: 0.4426 - val_accuracy: 0.8162\n",
      "Epoch 17/50\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.4251 - accuracy: 0.8239 - val_loss: 0.4462 - val_accuracy: 0.8133\n",
      "Epoch 18/50\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.4260 - accuracy: 0.8214 - val_loss: 0.4452 - val_accuracy: 0.8142\n",
      "Epoch 19/50\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.4257 - accuracy: 0.8216 - val_loss: 0.4433 - val_accuracy: 0.8142\n",
      "Epoch 20/50\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.4251 - accuracy: 0.8214 - val_loss: 0.4447 - val_accuracy: 0.8131\n",
      "Epoch 21/50\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.4219 - accuracy: 0.8225 - val_loss: 0.4457 - val_accuracy: 0.8153\n",
      "Epoch 22/50\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.4232 - accuracy: 0.8234 - val_loss: 0.4422 - val_accuracy: 0.8133\n",
      "Epoch 23/50\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.4218 - accuracy: 0.8237 - val_loss: 0.4448 - val_accuracy: 0.8167\n",
      "Epoch 24/50\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.4237 - accuracy: 0.8250 - val_loss: 0.4531 - val_accuracy: 0.8138\n",
      "Epoch 25/50\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.4220 - accuracy: 0.8233 - val_loss: 0.4469 - val_accuracy: 0.8167\n",
      "Epoch 26/50\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.4210 - accuracy: 0.8230 - val_loss: 0.4456 - val_accuracy: 0.8144\n",
      "Epoch 27/50\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.4200 - accuracy: 0.8232 - val_loss: 0.4458 - val_accuracy: 0.8122\n",
      "Epoch 28/50\n",
      "657/657 [==============================] - 2s 3ms/step - loss: 0.4210 - accuracy: 0.8229 - val_loss: 0.4461 - val_accuracy: 0.8122\n",
      "Epoch 29/50\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.4193 - accuracy: 0.8232 - val_loss: 0.4483 - val_accuracy: 0.8129\n",
      "Epoch 30/50\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.4184 - accuracy: 0.8240 - val_loss: 0.4439 - val_accuracy: 0.8149\n",
      "Epoch 31/50\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.4181 - accuracy: 0.8239 - val_loss: 0.4462 - val_accuracy: 0.8129\n",
      "Epoch 32/50\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.4177 - accuracy: 0.8233 - val_loss: 0.4444 - val_accuracy: 0.8133\n",
      "Epoch 33/50\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.4181 - accuracy: 0.8247 - val_loss: 0.4460 - val_accuracy: 0.8173\n",
      "Epoch 34/50\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.4160 - accuracy: 0.8244 - val_loss: 0.4474 - val_accuracy: 0.8160\n",
      "Epoch 35/50\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.4174 - accuracy: 0.8256 - val_loss: 0.4459 - val_accuracy: 0.8151\n",
      "Epoch 36/50\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.4169 - accuracy: 0.8234 - val_loss: 0.4449 - val_accuracy: 0.8113\n",
      "Epoch 37/50\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.4159 - accuracy: 0.8244 - val_loss: 0.4453 - val_accuracy: 0.8127\n",
      "Epoch 38/50\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.4172 - accuracy: 0.8238 - val_loss: 0.4459 - val_accuracy: 0.8147\n",
      "Epoch 39/50\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.4151 - accuracy: 0.8250 - val_loss: 0.4432 - val_accuracy: 0.8162\n",
      "Epoch 40/50\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.4151 - accuracy: 0.8258 - val_loss: 0.4444 - val_accuracy: 0.8151\n",
      "Epoch 41/50\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.4165 - accuracy: 0.8244 - val_loss: 0.4454 - val_accuracy: 0.8133\n",
      "Epoch 42/50\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.4146 - accuracy: 0.8257 - val_loss: 0.4452 - val_accuracy: 0.8129\n",
      "Epoch 43/50\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.4156 - accuracy: 0.8255 - val_loss: 0.4445 - val_accuracy: 0.8113\n",
      "Epoch 44/50\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.4147 - accuracy: 0.8252 - val_loss: 0.4439 - val_accuracy: 0.8158\n",
      "Epoch 45/50\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.4151 - accuracy: 0.8237 - val_loss: 0.4447 - val_accuracy: 0.8164\n",
      "Epoch 46/50\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.4140 - accuracy: 0.8239 - val_loss: 0.4449 - val_accuracy: 0.8144\n",
      "Epoch 47/50\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.4137 - accuracy: 0.8263 - val_loss: 0.4473 - val_accuracy: 0.8138\n",
      "Epoch 48/50\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.4119 - accuracy: 0.8265 - val_loss: 0.4488 - val_accuracy: 0.8120\n",
      "Epoch 49/50\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.4121 - accuracy: 0.8252 - val_loss: 0.4481 - val_accuracy: 0.8153\n",
      "Epoch 50/50\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.4116 - accuracy: 0.8277 - val_loss: 0.4449 - val_accuracy: 0.8162\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1fae6324790>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Entrenar el modelo\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a837fd56-b53a-4772-97e4-86810d041f0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4269 - accuracy: 0.8218\n",
      "Test accuracy: 0.8217777609825134\n"
     ]
    }
   ],
   "source": [
    "# Evaluar el modelo\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "728cc5e5-4f69-4b84-9242-730ddc9d3f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Import libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "45f7b7ed-5e38-4542-abe0-03ac6231b1b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>X10</th>\n",
       "      <th>...</th>\n",
       "      <th>X15</th>\n",
       "      <th>X16</th>\n",
       "      <th>X17</th>\n",
       "      <th>X18</th>\n",
       "      <th>X19</th>\n",
       "      <th>X20</th>\n",
       "      <th>X21</th>\n",
       "      <th>X22</th>\n",
       "      <th>X23</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>689</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>120000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3272</td>\n",
       "      <td>3455</td>\n",
       "      <td>3261</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>90000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>14331</td>\n",
       "      <td>14948</td>\n",
       "      <td>15549</td>\n",
       "      <td>1518</td>\n",
       "      <td>1500</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>28314</td>\n",
       "      <td>28959</td>\n",
       "      <td>29547</td>\n",
       "      <td>2000</td>\n",
       "      <td>2019</td>\n",
       "      <td>1200</td>\n",
       "      <td>1100</td>\n",
       "      <td>1069</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>50000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>20940</td>\n",
       "      <td>19146</td>\n",
       "      <td>19131</td>\n",
       "      <td>2000</td>\n",
       "      <td>36681</td>\n",
       "      <td>10000</td>\n",
       "      <td>9000</td>\n",
       "      <td>689</td>\n",
       "      <td>679</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       X1 X2 X3 X4  X5  X6 X7  X8  X9 X10  ...    X15    X16    X17   X18  \\\n",
       "1   20000  2  2  1  24   2  2  -1  -1  -2  ...      0      0      0     0   \n",
       "2  120000  2  2  2  26  -1  2   0   0   0  ...   3272   3455   3261     0   \n",
       "3   90000  2  2  2  34   0  0   0   0   0  ...  14331  14948  15549  1518   \n",
       "4   50000  2  2  1  37   0  0   0   0   0  ...  28314  28959  29547  2000   \n",
       "5   50000  1  2  1  57  -1  0  -1   0   0  ...  20940  19146  19131  2000   \n",
       "\n",
       "     X19    X20   X21   X22   X23  Y  \n",
       "1    689      0     0     0     0  1  \n",
       "2   1000   1000  1000     0  2000  1  \n",
       "3   1500   1000  1000  1000  5000  0  \n",
       "4   2019   1200  1100  1069  1000  0  \n",
       "5  36681  10000  9000   689   679  0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 2: Load and preprocess data\n",
    "# Load data from a CSV file\n",
    "df = pd.read_csv('dataset.csv')\n",
    "\n",
    "# Remove the first column if it's an index\n",
    "df = df.drop(df.columns[0], axis=1)\n",
    "df = df.iloc[1:]\n",
    "\n",
    "# Display the first 5 rows for quick inspection\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f0f9d618-0304-41b8-b554-99db196de81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Separate features and target variable\n",
    "# Separate the independent variables (X) and the dependent variable (y)\n",
    "X = df.drop('Y', axis=1)\n",
    "y = df['Y']\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "783ddb2e-53d3-4785-a74a-95d30d9ceaf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Split data into train, validation, and test sets\n",
    "# Split the data into training, validation, and test sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Convert labels to float\n",
    "y_train = y_train.astype(float)\n",
    "y_val = y_val.astype(float)\n",
    "y_test = y_test.astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6217598c-8826-4a57-8602-281909b5c7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Create and compile the model\n",
    "# Customizing the optimizer\n",
    "custom_optimizer = Adam(learning_rate=0.0005)\n",
    "\n",
    "# Create the model\n",
    "model = Sequential()\n",
    "model.add(Dense(128, activation='relu', input_shape=(X_train.shape[1],)))  # Increased neurons\n",
    "model.add(Dropout(0.3))  # Increased dropout\n",
    "model.add(Dense(64, activation='tanh'))  # Changed activation function\n",
    "model.add(Dropout(0.3))  # Increased dropout\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=custom_optimizer, loss='binary_crossentropy', metrics=['accuracy', 'Precision', 'Recall'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dd2fb810-e35e-4981-b326-9e49cd0630a1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "329/329 [==============================] - 2s 4ms/step - loss: 0.4989 - accuracy: 0.7898 - precision: 0.5724 - recall: 0.2207 - val_loss: 0.4609 - val_accuracy: 0.8064 - val_precision: 0.6119 - val_recall: 0.2663\n",
      "Epoch 2/100\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 0.4653 - accuracy: 0.8085 - precision: 0.6521 - recall: 0.2998 - val_loss: 0.4571 - val_accuracy: 0.8113 - val_precision: 0.6272 - val_recall: 0.2964\n",
      "Epoch 3/100\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 0.4568 - accuracy: 0.8124 - precision: 0.6696 - recall: 0.3112 - val_loss: 0.4509 - val_accuracy: 0.8131 - val_precision: 0.6336 - val_recall: 0.3047\n",
      "Epoch 4/100\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 0.4543 - accuracy: 0.8122 - precision: 0.6608 - recall: 0.3216 - val_loss: 0.4454 - val_accuracy: 0.8149 - val_precision: 0.6422 - val_recall: 0.3088\n",
      "Epoch 5/100\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 0.4483 - accuracy: 0.8146 - precision: 0.6687 - recall: 0.3319 - val_loss: 0.4495 - val_accuracy: 0.8138 - val_precision: 0.6288 - val_recall: 0.3212\n",
      "Epoch 6/100\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 0.4466 - accuracy: 0.8154 - precision: 0.6654 - recall: 0.3441 - val_loss: 0.4470 - val_accuracy: 0.8149 - val_precision: 0.6245 - val_recall: 0.3430\n",
      "Epoch 7/100\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 0.4459 - accuracy: 0.8152 - precision: 0.6613 - recall: 0.3486 - val_loss: 0.4453 - val_accuracy: 0.8151 - val_precision: 0.6248 - val_recall: 0.3451\n",
      "Epoch 8/100\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 0.4421 - accuracy: 0.8167 - precision: 0.6679 - recall: 0.3518 - val_loss: 0.4437 - val_accuracy: 0.8153 - val_precision: 0.6269 - val_recall: 0.3430\n",
      "Epoch 9/100\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 0.4412 - accuracy: 0.8170 - precision: 0.6660 - recall: 0.3578 - val_loss: 0.4439 - val_accuracy: 0.8144 - val_precision: 0.6217 - val_recall: 0.3440\n",
      "Epoch 10/100\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 0.4384 - accuracy: 0.8192 - precision: 0.6739 - recall: 0.3646 - val_loss: 0.4441 - val_accuracy: 0.8151 - val_precision: 0.6169 - val_recall: 0.3637\n",
      "Epoch 11/100\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 0.4390 - accuracy: 0.8173 - precision: 0.6646 - recall: 0.3627 - val_loss: 0.4435 - val_accuracy: 0.8156 - val_precision: 0.6195 - val_recall: 0.3627\n",
      "Epoch 12/100\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 0.4370 - accuracy: 0.8184 - precision: 0.6693 - recall: 0.3648 - val_loss: 0.4453 - val_accuracy: 0.8140 - val_precision: 0.6181 - val_recall: 0.3472\n",
      "Epoch 13/100\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 0.4356 - accuracy: 0.8187 - precision: 0.6678 - recall: 0.3693 - val_loss: 0.4441 - val_accuracy: 0.8156 - val_precision: 0.6162 - val_recall: 0.3710\n",
      "Epoch 14/100\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 0.4346 - accuracy: 0.8188 - precision: 0.6662 - recall: 0.3734 - val_loss: 0.4433 - val_accuracy: 0.8144 - val_precision: 0.6144 - val_recall: 0.3617\n",
      "Epoch 15/100\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 0.4345 - accuracy: 0.8208 - precision: 0.6767 - recall: 0.3738 - val_loss: 0.4433 - val_accuracy: 0.8153 - val_precision: 0.6264 - val_recall: 0.3440\n",
      "Epoch 16/100\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 0.4333 - accuracy: 0.8195 - precision: 0.6693 - recall: 0.3740 - val_loss: 0.4430 - val_accuracy: 0.8136 - val_precision: 0.6117 - val_recall: 0.3575\n",
      "Epoch 17/100\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 0.4338 - accuracy: 0.8191 - precision: 0.6653 - recall: 0.3779 - val_loss: 0.4432 - val_accuracy: 0.8140 - val_precision: 0.6123 - val_recall: 0.3617\n",
      "Epoch 18/100\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 0.4339 - accuracy: 0.8203 - precision: 0.6717 - recall: 0.3777 - val_loss: 0.4456 - val_accuracy: 0.8136 - val_precision: 0.6113 - val_recall: 0.3585\n",
      "Epoch 19/100\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 0.4344 - accuracy: 0.8174 - precision: 0.6587 - recall: 0.3732 - val_loss: 0.4435 - val_accuracy: 0.8151 - val_precision: 0.6203 - val_recall: 0.3554\n",
      "Epoch 20/100\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 0.4315 - accuracy: 0.8186 - precision: 0.6641 - recall: 0.3747 - val_loss: 0.4446 - val_accuracy: 0.8138 - val_precision: 0.6108 - val_recall: 0.3627\n",
      "Epoch 21/100\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 0.4308 - accuracy: 0.8195 - precision: 0.6658 - recall: 0.3805 - val_loss: 0.4427 - val_accuracy: 0.8153 - val_precision: 0.6284 - val_recall: 0.3399\n",
      "Epoch 22/100\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 0.4312 - accuracy: 0.8193 - precision: 0.6686 - recall: 0.3736 - val_loss: 0.4420 - val_accuracy: 0.8147 - val_precision: 0.6220 - val_recall: 0.3461\n",
      "Epoch 23/100\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 0.4312 - accuracy: 0.8201 - precision: 0.6687 - recall: 0.3811 - val_loss: 0.4430 - val_accuracy: 0.8136 - val_precision: 0.6154 - val_recall: 0.3482\n",
      "Epoch 24/100\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 0.4310 - accuracy: 0.8173 - precision: 0.6591 - recall: 0.3717 - val_loss: 0.4425 - val_accuracy: 0.8138 - val_precision: 0.6161 - val_recall: 0.3492\n",
      "Epoch 25/100\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 0.4305 - accuracy: 0.8209 - precision: 0.6710 - recall: 0.3834 - val_loss: 0.4430 - val_accuracy: 0.8140 - val_precision: 0.6151 - val_recall: 0.3544\n",
      "Epoch 26/100\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 0.4299 - accuracy: 0.8193 - precision: 0.6639 - recall: 0.3820 - val_loss: 0.4421 - val_accuracy: 0.8133 - val_precision: 0.6168 - val_recall: 0.3420\n",
      "Epoch 27/100\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 0.4296 - accuracy: 0.8188 - precision: 0.6620 - recall: 0.3807 - val_loss: 0.4413 - val_accuracy: 0.8142 - val_precision: 0.6219 - val_recall: 0.3409\n",
      "Epoch 28/100\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 0.4284 - accuracy: 0.8214 - precision: 0.6725 - recall: 0.3856 - val_loss: 0.4414 - val_accuracy: 0.8138 - val_precision: 0.6165 - val_recall: 0.3482\n",
      "Epoch 29/100\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 0.4289 - accuracy: 0.8213 - precision: 0.6724 - recall: 0.3849 - val_loss: 0.4422 - val_accuracy: 0.8138 - val_precision: 0.6200 - val_recall: 0.3399\n",
      "Epoch 30/100\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 0.4283 - accuracy: 0.8212 - precision: 0.6715 - recall: 0.3856 - val_loss: 0.4434 - val_accuracy: 0.8122 - val_precision: 0.6071 - val_recall: 0.3523\n",
      "Epoch 31/100\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 0.4277 - accuracy: 0.8202 - precision: 0.6679 - recall: 0.3832 - val_loss: 0.4422 - val_accuracy: 0.8156 - val_precision: 0.6266 - val_recall: 0.3461\n",
      "Epoch 32/100\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 0.4281 - accuracy: 0.8201 - precision: 0.6708 - recall: 0.3775 - val_loss: 0.4420 - val_accuracy: 0.8140 - val_precision: 0.6181 - val_recall: 0.3472\n",
      "Epoch 33/100\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 0.4285 - accuracy: 0.8202 - precision: 0.6685 - recall: 0.3817 - val_loss: 0.4424 - val_accuracy: 0.8140 - val_precision: 0.6151 - val_recall: 0.3544\n",
      "Epoch 34/100\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 0.4271 - accuracy: 0.8209 - precision: 0.6712 - recall: 0.3837 - val_loss: 0.4415 - val_accuracy: 0.8133 - val_precision: 0.6151 - val_recall: 0.3461\n",
      "Epoch 35/100\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 0.4263 - accuracy: 0.8214 - precision: 0.6702 - recall: 0.3899 - val_loss: 0.4418 - val_accuracy: 0.8149 - val_precision: 0.6299 - val_recall: 0.3316\n",
      "Epoch 36/100\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 0.4274 - accuracy: 0.8210 - precision: 0.6722 - recall: 0.3828 - val_loss: 0.4431 - val_accuracy: 0.8131 - val_precision: 0.6073 - val_recall: 0.3637\n",
      "Epoch 37/100\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 0.4262 - accuracy: 0.8210 - precision: 0.6689 - recall: 0.3888 - val_loss: 0.4418 - val_accuracy: 0.8147 - val_precision: 0.6220 - val_recall: 0.3461\n",
      "Epoch 38/100\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 0.4273 - accuracy: 0.8201 - precision: 0.6687 - recall: 0.3807 - val_loss: 0.4416 - val_accuracy: 0.8122 - val_precision: 0.6099 - val_recall: 0.3451\n",
      "Epoch 39/100\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 0.4265 - accuracy: 0.8214 - precision: 0.6732 - recall: 0.3845 - val_loss: 0.4431 - val_accuracy: 0.8156 - val_precision: 0.6301 - val_recall: 0.3389\n",
      "Epoch 40/100\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 0.4254 - accuracy: 0.8197 - precision: 0.6663 - recall: 0.3809 - val_loss: 0.4436 - val_accuracy: 0.8149 - val_precision: 0.6119 - val_recall: 0.3741\n",
      "Epoch 41/100\n",
      "329/329 [==============================] - 5s 15ms/step - loss: 0.4253 - accuracy: 0.8206 - precision: 0.6674 - recall: 0.3875 - val_loss: 0.4423 - val_accuracy: 0.8144 - val_precision: 0.6186 - val_recall: 0.3513\n",
      "Epoch 42/100\n",
      "329/329 [==============================] - 4s 12ms/step - loss: 0.4251 - accuracy: 0.8222 - precision: 0.6757 - recall: 0.3877 - val_loss: 0.4428 - val_accuracy: 0.8156 - val_precision: 0.6311 - val_recall: 0.3368\n",
      "Epoch 43/100\n",
      "329/329 [==============================] - 4s 13ms/step - loss: 0.4262 - accuracy: 0.8218 - precision: 0.6757 - recall: 0.3841 - val_loss: 0.4435 - val_accuracy: 0.8153 - val_precision: 0.6171 - val_recall: 0.3658\n",
      "Epoch 44/100\n",
      "329/329 [==============================] - 3s 10ms/step - loss: 0.4253 - accuracy: 0.8209 - precision: 0.6693 - recall: 0.3869 - val_loss: 0.4424 - val_accuracy: 0.8162 - val_precision: 0.6259 - val_recall: 0.3554\n",
      "Epoch 45/100\n",
      "329/329 [==============================] - 3s 8ms/step - loss: 0.4239 - accuracy: 0.8236 - precision: 0.6823 - recall: 0.3890 - val_loss: 0.4476 - val_accuracy: 0.8160 - val_precision: 0.6065 - val_recall: 0.4041\n",
      "Epoch 46/100\n",
      "329/329 [==============================] - 3s 8ms/step - loss: 0.4240 - accuracy: 0.8219 - precision: 0.6686 - recall: 0.3969 - val_loss: 0.4407 - val_accuracy: 0.8171 - val_precision: 0.6325 - val_recall: 0.3513\n",
      "Epoch 47/100\n",
      "329/329 [==============================] - 2s 6ms/step - loss: 0.4255 - accuracy: 0.8212 - precision: 0.6694 - recall: 0.3896 - val_loss: 0.4416 - val_accuracy: 0.8169 - val_precision: 0.6289 - val_recall: 0.3565\n",
      "Epoch 48/100\n",
      "329/329 [==============================] - 2s 5ms/step - loss: 0.4245 - accuracy: 0.8202 - precision: 0.6692 - recall: 0.3811 - val_loss: 0.4426 - val_accuracy: 0.8149 - val_precision: 0.6170 - val_recall: 0.3606\n",
      "Epoch 49/100\n",
      "329/329 [==============================] - 2s 5ms/step - loss: 0.4250 - accuracy: 0.8207 - precision: 0.6675 - recall: 0.3877 - val_loss: 0.4431 - val_accuracy: 0.8151 - val_precision: 0.6211 - val_recall: 0.3534\n",
      "Epoch 50/100\n",
      "329/329 [==============================] - 2s 5ms/step - loss: 0.4243 - accuracy: 0.8232 - precision: 0.6754 - recall: 0.3969 - val_loss: 0.4432 - val_accuracy: 0.8160 - val_precision: 0.6208 - val_recall: 0.3648\n",
      "Epoch 51/100\n",
      "329/329 [==============================] - 2s 5ms/step - loss: 0.4243 - accuracy: 0.8222 - precision: 0.6744 - recall: 0.3899 - val_loss: 0.4412 - val_accuracy: 0.8138 - val_precision: 0.6178 - val_recall: 0.3451\n",
      "Epoch 52/100\n",
      "329/329 [==============================] - 2s 6ms/step - loss: 0.4233 - accuracy: 0.8213 - precision: 0.6736 - recall: 0.3830 - val_loss: 0.4420 - val_accuracy: 0.8164 - val_precision: 0.6213 - val_recall: 0.3689\n",
      "Epoch 53/100\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 0.4239 - accuracy: 0.8209 - precision: 0.6709 - recall: 0.3841 - val_loss: 0.4418 - val_accuracy: 0.8162 - val_precision: 0.6186 - val_recall: 0.3731\n",
      "Epoch 54/100\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 0.4236 - accuracy: 0.8220 - precision: 0.6718 - recall: 0.3918 - val_loss: 0.4434 - val_accuracy: 0.8153 - val_precision: 0.6120 - val_recall: 0.3793\n",
      "Epoch 55/100\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 0.4218 - accuracy: 0.8210 - precision: 0.6680 - recall: 0.3899 - val_loss: 0.4432 - val_accuracy: 0.8156 - val_precision: 0.6230 - val_recall: 0.3544\n",
      "Epoch 56/100\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 0.4228 - accuracy: 0.8222 - precision: 0.6713 - recall: 0.3948 - val_loss: 0.4410 - val_accuracy: 0.8160 - val_precision: 0.6271 - val_recall: 0.3503\n",
      "Epoch 57/100\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 0.4229 - accuracy: 0.8215 - precision: 0.6730 - recall: 0.3860 - val_loss: 0.4437 - val_accuracy: 0.8167 - val_precision: 0.6264 - val_recall: 0.3596\n",
      "Epoch 58/100\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 0.4221 - accuracy: 0.8235 - precision: 0.6780 - recall: 0.3950 - val_loss: 0.4417 - val_accuracy: 0.8151 - val_precision: 0.6281 - val_recall: 0.3378\n",
      "Epoch 59/100\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 0.4216 - accuracy: 0.8219 - precision: 0.6739 - recall: 0.3875 - val_loss: 0.4448 - val_accuracy: 0.8140 - val_precision: 0.6107 - val_recall: 0.3658\n",
      "Epoch 60/100\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 0.4223 - accuracy: 0.8206 - precision: 0.6680 - recall: 0.3860 - val_loss: 0.4435 - val_accuracy: 0.8153 - val_precision: 0.6163 - val_recall: 0.3679\n",
      "Epoch 61/100\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 0.4220 - accuracy: 0.8226 - precision: 0.6751 - recall: 0.3920 - val_loss: 0.4439 - val_accuracy: 0.8153 - val_precision: 0.6214 - val_recall: 0.3554\n",
      "Epoch 62/100\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 0.4198 - accuracy: 0.8221 - precision: 0.6718 - recall: 0.3931 - val_loss: 0.4428 - val_accuracy: 0.8151 - val_precision: 0.6354 - val_recall: 0.3233\n",
      "Epoch 63/100\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 0.4209 - accuracy: 0.8222 - precision: 0.6783 - recall: 0.3832 - val_loss: 0.4447 - val_accuracy: 0.8151 - val_precision: 0.6096 - val_recall: 0.3834\n",
      "Epoch 64/100\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 0.4214 - accuracy: 0.8231 - precision: 0.6723 - recall: 0.4010 - val_loss: 0.4461 - val_accuracy: 0.8158 - val_precision: 0.6245 - val_recall: 0.3534\n",
      "Epoch 65/100\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 0.4195 - accuracy: 0.8230 - precision: 0.6775 - recall: 0.3918 - val_loss: 0.4457 - val_accuracy: 0.8149 - val_precision: 0.6142 - val_recall: 0.3679\n",
      "Epoch 66/100\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 0.4209 - accuracy: 0.8235 - precision: 0.6766 - recall: 0.3969 - val_loss: 0.4415 - val_accuracy: 0.8158 - val_precision: 0.6355 - val_recall: 0.3306\n",
      "Epoch 67/100\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 0.4209 - accuracy: 0.8227 - precision: 0.6767 - recall: 0.3903 - val_loss: 0.4430 - val_accuracy: 0.8153 - val_precision: 0.6245 - val_recall: 0.3482\n",
      "Epoch 68/100\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 0.4222 - accuracy: 0.8207 - precision: 0.6708 - recall: 0.3826 - val_loss: 0.4423 - val_accuracy: 0.8149 - val_precision: 0.6191 - val_recall: 0.3554\n",
      "Epoch 69/100\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 0.4206 - accuracy: 0.8219 - precision: 0.6740 - recall: 0.3877 - val_loss: 0.4431 - val_accuracy: 0.8140 - val_precision: 0.6127 - val_recall: 0.3606\n",
      "Epoch 70/100\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 0.4194 - accuracy: 0.8231 - precision: 0.6784 - recall: 0.3911 - val_loss: 0.4430 - val_accuracy: 0.8144 - val_precision: 0.6144 - val_recall: 0.3617\n",
      "Epoch 71/100\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 0.4197 - accuracy: 0.8235 - precision: 0.6771 - recall: 0.3961 - val_loss: 0.4444 - val_accuracy: 0.8140 - val_precision: 0.6088 - val_recall: 0.3710\n",
      "Epoch 72/100\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 0.4215 - accuracy: 0.8233 - precision: 0.6764 - recall: 0.3961 - val_loss: 0.4431 - val_accuracy: 0.8151 - val_precision: 0.6234 - val_recall: 0.3482\n",
      "Epoch 73/100\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 0.4211 - accuracy: 0.8205 - precision: 0.6653 - recall: 0.3903 - val_loss: 0.4427 - val_accuracy: 0.8149 - val_precision: 0.6204 - val_recall: 0.3523\n",
      "Epoch 74/100\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 0.4201 - accuracy: 0.8238 - precision: 0.6785 - recall: 0.3967 - val_loss: 0.4435 - val_accuracy: 0.8149 - val_precision: 0.6150 - val_recall: 0.3658\n",
      "Epoch 75/100\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 0.4194 - accuracy: 0.8225 - precision: 0.6745 - recall: 0.3922 - val_loss: 0.4423 - val_accuracy: 0.8147 - val_precision: 0.6143 - val_recall: 0.3648\n",
      "Epoch 76/100\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 0.4185 - accuracy: 0.8240 - precision: 0.6782 - recall: 0.3984 - val_loss: 0.4416 - val_accuracy: 0.8160 - val_precision: 0.6252 - val_recall: 0.3544\n",
      "Epoch 77/100\n",
      "329/329 [==============================] - 2s 5ms/step - loss: 0.4195 - accuracy: 0.8238 - precision: 0.6793 - recall: 0.3950 - val_loss: 0.4420 - val_accuracy: 0.8158 - val_precision: 0.6269 - val_recall: 0.3482\n",
      "Epoch 78/100\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 0.4192 - accuracy: 0.8239 - precision: 0.6829 - recall: 0.3901 - val_loss: 0.4429 - val_accuracy: 0.8169 - val_precision: 0.6270 - val_recall: 0.3606\n",
      "Epoch 79/100\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 0.4185 - accuracy: 0.8239 - precision: 0.6780 - recall: 0.3980 - val_loss: 0.4433 - val_accuracy: 0.8176 - val_precision: 0.6272 - val_recall: 0.3679\n",
      "Epoch 80/100\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 0.4188 - accuracy: 0.8224 - precision: 0.6733 - recall: 0.3935 - val_loss: 0.4415 - val_accuracy: 0.8180 - val_precision: 0.6357 - val_recall: 0.3544\n",
      "Epoch 81/100\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 0.4188 - accuracy: 0.8238 - precision: 0.6800 - recall: 0.3939 - val_loss: 0.4413 - val_accuracy: 0.8160 - val_precision: 0.6276 - val_recall: 0.3492\n",
      "Epoch 82/100\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 0.4193 - accuracy: 0.8223 - precision: 0.6777 - recall: 0.3854 - val_loss: 0.4418 - val_accuracy: 0.8167 - val_precision: 0.6273 - val_recall: 0.3575\n",
      "Epoch 83/100\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 0.4192 - accuracy: 0.8231 - precision: 0.6780 - recall: 0.3918 - val_loss: 0.4424 - val_accuracy: 0.8169 - val_precision: 0.6243 - val_recall: 0.3668\n",
      "Epoch 84/100\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 0.4195 - accuracy: 0.8238 - precision: 0.6797 - recall: 0.3948 - val_loss: 0.4412 - val_accuracy: 0.8173 - val_precision: 0.6399 - val_recall: 0.3389\n",
      "Epoch 85/100\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 0.4173 - accuracy: 0.8236 - precision: 0.6800 - recall: 0.3926 - val_loss: 0.4416 - val_accuracy: 0.8144 - val_precision: 0.6165 - val_recall: 0.3565\n",
      "Epoch 86/100\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 0.4182 - accuracy: 0.8235 - precision: 0.6786 - recall: 0.3941 - val_loss: 0.4413 - val_accuracy: 0.8171 - val_precision: 0.6282 - val_recall: 0.3606\n",
      "Epoch 87/100\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 0.4184 - accuracy: 0.8236 - precision: 0.6797 - recall: 0.3931 - val_loss: 0.4413 - val_accuracy: 0.8182 - val_precision: 0.6369 - val_recall: 0.3544\n",
      "Epoch 88/100\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 0.4186 - accuracy: 0.8237 - precision: 0.6794 - recall: 0.3944 - val_loss: 0.4431 - val_accuracy: 0.8162 - val_precision: 0.6287 - val_recall: 0.3492\n",
      "Epoch 89/100\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 0.4194 - accuracy: 0.8225 - precision: 0.6741 - recall: 0.3929 - val_loss: 0.4429 - val_accuracy: 0.8160 - val_precision: 0.6208 - val_recall: 0.3648\n",
      "Epoch 90/100\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 0.4182 - accuracy: 0.8234 - precision: 0.6740 - recall: 0.4006 - val_loss: 0.4416 - val_accuracy: 0.8156 - val_precision: 0.6190 - val_recall: 0.3637\n",
      "Epoch 91/100\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 0.4176 - accuracy: 0.8214 - precision: 0.6700 - recall: 0.3903 - val_loss: 0.4411 - val_accuracy: 0.8178 - val_precision: 0.6306 - val_recall: 0.3627\n",
      "Epoch 92/100\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 0.4176 - accuracy: 0.8248 - precision: 0.6819 - recall: 0.3993 - val_loss: 0.4432 - val_accuracy: 0.8158 - val_precision: 0.6164 - val_recall: 0.3731\n",
      "Epoch 93/100\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 0.4192 - accuracy: 0.8230 - precision: 0.6775 - recall: 0.3909 - val_loss: 0.4420 - val_accuracy: 0.8164 - val_precision: 0.6252 - val_recall: 0.3596\n",
      "Epoch 94/100\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 0.4171 - accuracy: 0.8242 - precision: 0.6840 - recall: 0.3916 - val_loss: 0.4442 - val_accuracy: 0.8131 - val_precision: 0.6054 - val_recall: 0.3689\n",
      "Epoch 95/100\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 0.4179 - accuracy: 0.8236 - precision: 0.6747 - recall: 0.4014 - val_loss: 0.4427 - val_accuracy: 0.8147 - val_precision: 0.6123 - val_recall: 0.3699\n",
      "Epoch 96/100\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 0.4168 - accuracy: 0.8231 - precision: 0.6762 - recall: 0.3948 - val_loss: 0.4434 - val_accuracy: 0.8144 - val_precision: 0.6076 - val_recall: 0.3803\n",
      "Epoch 97/100\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 0.4184 - accuracy: 0.8225 - precision: 0.6731 - recall: 0.3941 - val_loss: 0.4446 - val_accuracy: 0.8156 - val_precision: 0.6162 - val_recall: 0.3710\n",
      "Epoch 98/100\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 0.4181 - accuracy: 0.8239 - precision: 0.6799 - recall: 0.3952 - val_loss: 0.4428 - val_accuracy: 0.8158 - val_precision: 0.6156 - val_recall: 0.3751\n",
      "Epoch 99/100\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 0.4169 - accuracy: 0.8254 - precision: 0.6857 - recall: 0.3988 - val_loss: 0.4441 - val_accuracy: 0.8156 - val_precision: 0.6123 - val_recall: 0.3813\n",
      "Epoch 100/100\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 0.4162 - accuracy: 0.8242 - precision: 0.6797 - recall: 0.3984 - val_loss: 0.4430 - val_accuracy: 0.8158 - val_precision: 0.6164 - val_recall: 0.3731\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1fae8fc0050>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 6: Train the model\n",
    "# Train the model with different batch size and epochs\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=64, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e3b1b9d6-fe1f-4a3f-967d-d5f9f4102d92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 0s 2ms/step - loss: 0.4223 - accuracy: 0.8213 - precision: 0.6678 - recall: 0.3819\n",
      "Test accuracy: 0.8213333487510681\n",
      "Test precision: 0.6678383350372314\n",
      "Test recall: 0.3819095492362976\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: Evaluate the model\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_accuracy, test_precision, test_recall = model.evaluate(X_test, y_test)\n",
    "print(f\"Test accuracy: {test_accuracy}\")\n",
    "print(f\"Test precision: {test_precision}\")\n",
    "print(f\"Test recall: {test_recall}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d5140127-2be3-4e96-8fc1-bb4e592e05fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "# Load the data from CSV file\n",
    "df = pd.read_csv('dataset.csv')\n",
    "\n",
    "# Drop the first column if it's an unnecessary index column\n",
    "df = df.drop(df.columns[0], axis=1)\n",
    "df = df.iloc[1:]\n",
    "\n",
    "# Split data into features (X) and labels (y)\n",
    "X = df.drop('Y', axis=1)\n",
    "y = df['Y']\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split the data into training, validation, and test sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "y_train = y_train.astype(float)\n",
    "y_val = y_val.astype(float)\n",
    "y_test = y_test.astype(float)\n",
    "\n",
    "# Build the model\n",
    "model = Sequential()\n",
    "model.add(Dense(30, input_dim=X_train.shape[1], activation='relu', kernel_initializer='normal'))\n",
    "model.add(Dense(15, activation='relu'))\n",
    "model.add(Dense(5, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6eddf87b-883e-457e-801b-136bef84e071",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "history = model.fit(X_train, y_train, batch_size=50, epochs=100, validation_data=(X_val, y_val), verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b5ac029a-8d96-46f6-b073-d5db4255b3d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "657/657 [==============================] - 1s 1ms/step\n",
      "Accuracy score of train data : 0.8312380952380952\n",
      "Train data f1 score: 0.5005636978579482\n",
      "141/141 [==============================] - 0s 1ms/step\n",
      "Accuracy score of validation data : 0.8137777777777778\n",
      "Validation data f1 score: 0.426027397260274\n",
      "141/141 [==============================] - 0s 1ms/step\n",
      "Accuracy score of test data : 0.8186666666666667\n",
      "Test data f1 score: 0.4588859416445623\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on training data\n",
    "y_train_pred_prob = model.predict(X_train)\n",
    "y_train_pred = (y_train_pred_prob > 0.5).astype(\"int32\").flatten()\n",
    "f1_train = f1_score(y_train, y_train_pred)\n",
    "print('Accuracy score of train data :', accuracy_score(y_train, y_train_pred))\n",
    "print(\"Train data f1 score:\", f1_train)\n",
    "\n",
    "# Evaluate on validation data\n",
    "y_val_pred_prob = model.predict(X_val)\n",
    "y_val_pred = (y_val_pred_prob > 0.5).astype(\"int32\").flatten()\n",
    "f1_val = f1_score(y_val, y_val_pred)\n",
    "print('Accuracy score of validation data :', accuracy_score(y_val, y_val_pred))\n",
    "print(\"Validation data f1 score:\", f1_val)\n",
    "\n",
    "# Evaluate on test data (optional)\n",
    "y_test_pred_prob = model.predict(X_test)\n",
    "y_test_pred = (y_test_pred_prob > 0.5).astype(\"int32\").flatten()\n",
    "f1_test = f1_score(y_test, y_test_pred)\n",
    "print('Accuracy score of test data :', accuracy_score(y_test, y_test_pred))\n",
    "print(\"Test data f1 score:\", f1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a48d4251-fd62-430e-81c1-106f41eaa6cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "563/563 [==============================] - 14s 21ms/step - loss: 0.5087 - accuracy: 0.7811 - val_loss: 0.4874 - val_accuracy: 0.7930\n",
      "Epoch 2/10\n",
      "563/563 [==============================] - 12s 21ms/step - loss: 0.4892 - accuracy: 0.7912 - val_loss: 0.4701 - val_accuracy: 0.7980\n",
      "Epoch 3/10\n",
      "563/563 [==============================] - 12s 21ms/step - loss: 0.4814 - accuracy: 0.7952 - val_loss: 0.4844 - val_accuracy: 0.7992\n",
      "Epoch 4/10\n",
      "563/563 [==============================] - 12s 21ms/step - loss: 0.4763 - accuracy: 0.7948 - val_loss: 0.4685 - val_accuracy: 0.8028\n",
      "Epoch 5/10\n",
      "563/563 [==============================] - 12s 21ms/step - loss: 0.4716 - accuracy: 0.7979 - val_loss: 0.4613 - val_accuracy: 0.8002\n",
      "Epoch 6/10\n",
      "563/563 [==============================] - 12s 21ms/step - loss: 0.4699 - accuracy: 0.7990 - val_loss: 0.4599 - val_accuracy: 0.8028\n",
      "Epoch 7/10\n",
      "563/563 [==============================] - 12s 21ms/step - loss: 0.4664 - accuracy: 0.8011 - val_loss: 0.4803 - val_accuracy: 0.7958\n",
      "Epoch 8/10\n",
      "563/563 [==============================] - 12s 21ms/step - loss: 0.4680 - accuracy: 0.7987 - val_loss: 0.4598 - val_accuracy: 0.7988\n",
      "Epoch 9/10\n",
      "563/563 [==============================] - 12s 21ms/step - loss: 0.4654 - accuracy: 0.8032 - val_loss: 0.4743 - val_accuracy: 0.8040\n",
      "Epoch 10/10\n",
      "563/563 [==============================] - 12s 22ms/step - loss: 0.4651 - accuracy: 0.8005 - val_loss: 0.4635 - val_accuracy: 0.8018\n",
      "188/188 [==============================] - 1s 6ms/step\n",
      "Validation F1: 0.2833031946955997\n",
      "Validation Accuracy: 0.8018333333333333\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming df is your DataFrame and \"Y\" is your target variable\n",
    "df = pd.read_csv(\"dataset.csv\")\n",
    "\n",
    "# Remove the first column if it's an index\n",
    "df = df.drop(df.columns[0], axis=1)\n",
    "df = df.iloc[1:]\n",
    "\n",
    "# Split the data into features and target label\n",
    "X = df.drop('Y', axis=1)\n",
    "y = df['Y']\n",
    "\n",
    "# Splitting the dataset into training, validation, and test sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Convert labels to float\n",
    "y_train = y_train.astype(float)\n",
    "y_val = y_val.astype(float)\n",
    "y_test = y_test.astype('float')\n",
    "\n",
    "# Standardize the features (You can also use other preprocessing methods)\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Transformer layer\n",
    "def transformer_encoder(inputs, head_size, num_heads):\n",
    "    # Normalization and Attention\n",
    "    x = tf.keras.layers.LayerNormalization(epsilon=1e-6)(inputs)\n",
    "    x = tf.keras.layers.MultiHeadAttention(key_dim=head_size, num_heads=num_heads, dropout=0.3)(x, x)\n",
    "    x = tf.keras.layers.Dropout(0.3)(x)\n",
    "    res = x + inputs\n",
    "    \n",
    "    # Feed Forward Part\n",
    "    x = tf.keras.layers.LayerNormalization(epsilon=1e-6)(res)\n",
    "    x = tf.keras.layers.Conv1D(filters=head_size*2, kernel_size=1, activation='relu')(x)\n",
    "    x = tf.keras.layers.Dropout(0.3)(x)\n",
    "    x = tf.keras.layers.Conv1D(filters=head_size, kernel_size=1)(x)\n",
    "    return x + res\n",
    "\n",
    "# Inputs\n",
    "inputs = tf.keras.Input(shape=(X_train.shape[1], 1))\n",
    "\n",
    "# Initial Conv layer\n",
    "x = tf.keras.layers.Conv1D(filters=64, kernel_size=1, activation='relu')(inputs)\n",
    "\n",
    "# Transformer Encoder\n",
    "x = transformer_encoder(x, head_size=64, num_heads=4)\n",
    "\n",
    "# Global pooling and final Dense\n",
    "x = tf.keras.layers.GlobalAveragePooling1D()(x)\n",
    "outputs = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "# Compile and Run\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Note: X_train, X_val must have an extra dimension for the Conv1D layers\n",
    "history = model.fit(\n",
    "    X_train[:, :, None], y_train,\n",
    "    validation_data=(X_val[:, :, None], y_val),\n",
    "    epochs=10,\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "# Prediction\n",
    "y_val_pred = (model.predict(X_val[:, :, None]) > 0.5).astype(\"int32\")\n",
    "\n",
    "# Evaluate with f1-score & accuracy since the problem is a binary classification problem\n",
    "print('Validation F1:', f1_score(y_val, y_val_pred))\n",
    "print('Validation Accuracy:', accuracy_score(y_val, y_val_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c2f38adf-b0a5-4dca-a6e3-a23412935189",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c020c72a-7903-4348-ae46-f2a0544d79ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming df is your DataFrame and \"Y\" is your target variable\n",
    "df = pd.read_csv(\"dataset.csv\")\n",
    "\n",
    "# Remove the first column if it's an index\n",
    "df = df.drop(df.columns[0], axis=1)\n",
    "df = df.iloc[1:]\n",
    "\n",
    "# Split the data into features and target label\n",
    "X = df.drop('Y', axis=1)\n",
    "y = df['Y']\n",
    "\n",
    "# Splitting the dataset into training, validation, and test sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c8790149-43fd-428a-81d6-99dadbf26b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert labels to float\n",
    "y_train = y_train.astype(float)\n",
    "y_val = y_val.astype(float)\n",
    "y_test = y_test.astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fa84e810-8b95-4201-8111-91b862a9da95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the features (You can also use other preprocessing methods)\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b8f4d013-f81d-4018-ae92-af683b237e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a Sequential model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cce4bfb8-604d-4f42-b847-a3e8c02f7047",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "563/563 [==============================] - 2s 3ms/step - loss: 0.5028 - accuracy: 0.7993 - val_loss: 0.4595 - val_accuracy: 0.8153\n",
      "Epoch 2/25\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 0.4709 - accuracy: 0.8103 - val_loss: 0.4452 - val_accuracy: 0.8175\n",
      "Epoch 3/25\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 0.4578 - accuracy: 0.8132 - val_loss: 0.4390 - val_accuracy: 0.8198\n",
      "Epoch 4/25\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 0.4512 - accuracy: 0.8141 - val_loss: 0.4361 - val_accuracy: 0.8200\n",
      "Epoch 5/25\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 0.4464 - accuracy: 0.8151 - val_loss: 0.4337 - val_accuracy: 0.8205\n",
      "Epoch 6/25\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 0.4463 - accuracy: 0.8152 - val_loss: 0.4321 - val_accuracy: 0.8230\n",
      "Epoch 7/25\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 0.4422 - accuracy: 0.8179 - val_loss: 0.4311 - val_accuracy: 0.8215\n",
      "Epoch 8/25\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 0.4401 - accuracy: 0.8212 - val_loss: 0.4306 - val_accuracy: 0.8242\n",
      "Epoch 9/25\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 0.4397 - accuracy: 0.8198 - val_loss: 0.4344 - val_accuracy: 0.8235\n",
      "Epoch 10/25\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 0.4386 - accuracy: 0.8188 - val_loss: 0.4302 - val_accuracy: 0.8242\n",
      "Epoch 11/25\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 0.4374 - accuracy: 0.8192 - val_loss: 0.4297 - val_accuracy: 0.8213\n",
      "Epoch 12/25\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 0.4378 - accuracy: 0.8171 - val_loss: 0.4293 - val_accuracy: 0.8220\n",
      "Epoch 13/25\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 0.4357 - accuracy: 0.8194 - val_loss: 0.4290 - val_accuracy: 0.8230\n",
      "Epoch 14/25\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 0.4353 - accuracy: 0.8180 - val_loss: 0.4311 - val_accuracy: 0.8220\n",
      "Epoch 15/25\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 0.4346 - accuracy: 0.8196 - val_loss: 0.4302 - val_accuracy: 0.8227\n",
      "Epoch 16/25\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 0.4343 - accuracy: 0.8202 - val_loss: 0.4282 - val_accuracy: 0.8220\n",
      "Epoch 17/25\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 0.4365 - accuracy: 0.8181 - val_loss: 0.4304 - val_accuracy: 0.8207\n",
      "Epoch 18/25\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 0.4330 - accuracy: 0.8225 - val_loss: 0.4290 - val_accuracy: 0.8235\n",
      "Epoch 19/25\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 0.4341 - accuracy: 0.8183 - val_loss: 0.4286 - val_accuracy: 0.8223\n",
      "Epoch 20/25\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 0.4306 - accuracy: 0.8208 - val_loss: 0.4292 - val_accuracy: 0.8222\n",
      "Epoch 21/25\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 0.4308 - accuracy: 0.8212 - val_loss: 0.4292 - val_accuracy: 0.8205\n",
      "Epoch 22/25\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 0.4296 - accuracy: 0.8222 - val_loss: 0.4285 - val_accuracy: 0.8207\n",
      "Epoch 23/25\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 0.4312 - accuracy: 0.8197 - val_loss: 0.4303 - val_accuracy: 0.8223\n",
      "Epoch 24/25\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 0.4281 - accuracy: 0.8223 - val_loss: 0.4277 - val_accuracy: 0.8220\n",
      "Epoch 25/25\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 0.4309 - accuracy: 0.8221 - val_loss: 0.4285 - val_accuracy: 0.8200\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(X_train, y_train,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    epochs=25,\n",
    "                    batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9c096872-7fa7-45f8-8b37-3782f124993c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188/188 [==============================] - 0s 1ms/step\n",
      "Validation F1: 0.4551020408163265\n",
      "Validation Accuracy: 0.822\n"
     ]
    }
   ],
   "source": [
    "# Prediction\n",
    "y_val_pred = (model.predict(X_val[:, :, None]) > 0.5).astype(\"int32\")\n",
    "\n",
    "# Evaluate with f1-score & accuracy since the problem is a binary classification problem\n",
    "print('Validation F1:', f1_score(y_val, y_val_pred))\n",
    "print('Validation Accuracy:', accuracy_score(y_val, y_val_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a739b3ca-0f15-4f3c-acb5-7385f3bfff15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188/188 [==============================] - 0s 1ms/step\n",
      "Hidden Units: 32, Activation: relu, Optimizer: adam, Loss: binary_crossentropy, Accuracy: 0.8231666666666667\n",
      "188/188 [==============================] - 0s 1ms/step\n",
      "Hidden Units: 32, Activation: relu, Optimizer: sgd, Loss: binary_crossentropy, Accuracy: 0.8131666666666667\n",
      "188/188 [==============================] - 0s 1ms/step\n",
      "Hidden Units: 32, Activation: tanh, Optimizer: adam, Loss: binary_crossentropy, Accuracy: 0.8225\n",
      "188/188 [==============================] - 0s 1ms/step\n",
      "Hidden Units: 32, Activation: tanh, Optimizer: sgd, Loss: binary_crossentropy, Accuracy: 0.8206666666666667\n",
      "188/188 [==============================] - 0s 1ms/step\n",
      "Hidden Units: 64, Activation: relu, Optimizer: adam, Loss: binary_crossentropy, Accuracy: 0.823\n",
      "188/188 [==============================] - 0s 1ms/step\n",
      "Hidden Units: 64, Activation: relu, Optimizer: sgd, Loss: binary_crossentropy, Accuracy: 0.817\n",
      "188/188 [==============================] - 0s 1ms/step\n",
      "Hidden Units: 64, Activation: tanh, Optimizer: adam, Loss: binary_crossentropy, Accuracy: 0.8238333333333333\n",
      "188/188 [==============================] - 0s 1ms/step\n",
      "Hidden Units: 64, Activation: tanh, Optimizer: sgd, Loss: binary_crossentropy, Accuracy: 0.8166666666666667\n",
      "188/188 [==============================] - 0s 1ms/step\n",
      "Hidden Units: 128, Activation: relu, Optimizer: adam, Loss: binary_crossentropy, Accuracy: 0.8206666666666667\n",
      "188/188 [==============================] - 0s 1ms/step\n",
      "Hidden Units: 128, Activation: relu, Optimizer: sgd, Loss: binary_crossentropy, Accuracy: 0.8163333333333334\n",
      "188/188 [==============================] - 0s 1ms/step\n",
      "Hidden Units: 128, Activation: tanh, Optimizer: adam, Loss: binary_crossentropy, Accuracy: 0.8193333333333334\n",
      "188/188 [==============================] - 0s 1ms/step\n",
      "Hidden Units: 128, Activation: tanh, Optimizer: sgd, Loss: binary_crossentropy, Accuracy: 0.8158333333333333\n",
      "Best Validation Accuracy:  0.8238333333333333\n"
     ]
    }
   ],
   "source": [
    "# Standardize your input and split the data into training and validation sets\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "\n",
    "# Hyperparameter settings you want to try\n",
    "n_hidden_units = [32, 64, 128]\n",
    "activations = ['relu', 'tanh']\n",
    "optimizers = ['adam', 'sgd']\n",
    "losses = ['binary_crossentropy']\n",
    "\n",
    "# To store the best model\n",
    "best_model = None\n",
    "best_accuracy = 0.0\n",
    "\n",
    "# Nested loop to try different hyperparameters\n",
    "for units in n_hidden_units:\n",
    "    for activation in activations:\n",
    "        for optimizer in optimizers:\n",
    "            for loss in losses:\n",
    "                # Create model\n",
    "                model = tf.keras.Sequential()\n",
    "                model.add(tf.keras.layers.Dense(units, activation=activation, input_shape=(X_train.shape[1],)))\n",
    "                model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "                \n",
    "                # Compile model\n",
    "                model.compile(loss=loss, optimizer=optimizer, metrics=['accuracy'])\n",
    "                \n",
    "                # Fit model (You can also add validation data here)\n",
    "                model.fit(X_train, y_train, epochs=10, batch_size=32, verbose=0)\n",
    "                \n",
    "                # Evaluate model\n",
    "                y_val_pred = (model.predict(X_val) > 0.5).astype(\"int32\")\n",
    "                acc = accuracy_score(y_val, y_val_pred)\n",
    "                \n",
    "                print(f\"Hidden Units: {units}, Activation: {activation}, Optimizer: {optimizer}, Loss: {loss}, Accuracy: {acc}\")\n",
    "                \n",
    "                # Store the best model\n",
    "                if acc > best_accuracy:\n",
    "                    best_accuracy = acc\n",
    "                    best_model = model\n",
    "\n",
    "print(\"Best Validation Accuracy: \", best_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8dd16720-50fb-4b88-ab4f-eb35c2bed762",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188/188 [==============================] - 0s 1ms/step\n",
      "Units: 32, Activation: relu, Optimizer: adam, Loss: binary_crossentropy, Epochs: 10, Batch Size: 32, Accuracy: 0.819\n",
      "188/188 [==============================] - 0s 1ms/step\n",
      "Units: 32, Activation: relu, Optimizer: adam, Loss: binary_crossentropy, Epochs: 10, Batch Size: 64, Accuracy: 0.8226666666666667\n",
      "188/188 [==============================] - 0s 1ms/step\n",
      "Units: 32, Activation: relu, Optimizer: adam, Loss: binary_crossentropy, Epochs: 20, Batch Size: 32, Accuracy: 0.8203333333333334\n",
      "188/188 [==============================] - 0s 1ms/step\n",
      "Units: 32, Activation: relu, Optimizer: adam, Loss: binary_crossentropy, Epochs: 20, Batch Size: 64, Accuracy: 0.8235\n",
      "188/188 [==============================] - 0s 1ms/step\n",
      "Units: 32, Activation: relu, Optimizer: adam, Loss: binary_crossentropy, Epochs: 50, Batch Size: 32, Accuracy: 0.8213333333333334\n",
      "188/188 [==============================] - 0s 1ms/step\n",
      "Units: 32, Activation: relu, Optimizer: adam, Loss: binary_crossentropy, Epochs: 50, Batch Size: 64, Accuracy: 0.8176666666666667\n",
      "188/188 [==============================] - 0s 1ms/step\n",
      "Units: 32, Activation: relu, Optimizer: sgd, Loss: binary_crossentropy, Epochs: 10, Batch Size: 32, Accuracy: 0.8135\n",
      "188/188 [==============================] - 0s 1ms/step\n",
      "Units: 32, Activation: relu, Optimizer: sgd, Loss: binary_crossentropy, Epochs: 10, Batch Size: 64, Accuracy: 0.8146666666666667\n",
      "188/188 [==============================] - 0s 1ms/step\n",
      "Units: 32, Activation: relu, Optimizer: sgd, Loss: binary_crossentropy, Epochs: 20, Batch Size: 32, Accuracy: 0.822\n",
      "188/188 [==============================] - 0s 1ms/step\n",
      "Units: 32, Activation: relu, Optimizer: sgd, Loss: binary_crossentropy, Epochs: 20, Batch Size: 64, Accuracy: 0.8161666666666667\n",
      "188/188 [==============================] - 0s 1ms/step\n",
      "Units: 32, Activation: relu, Optimizer: sgd, Loss: binary_crossentropy, Epochs: 50, Batch Size: 32, Accuracy: 0.8228333333333333\n",
      "188/188 [==============================] - 0s 1ms/step\n",
      "Units: 32, Activation: relu, Optimizer: sgd, Loss: binary_crossentropy, Epochs: 50, Batch Size: 64, Accuracy: 0.8223333333333334\n",
      "188/188 [==============================] - 0s 1ms/step\n",
      "Units: 32, Activation: tanh, Optimizer: adam, Loss: binary_crossentropy, Epochs: 10, Batch Size: 32, Accuracy: 0.8211666666666667\n",
      "188/188 [==============================] - 0s 1ms/step\n",
      "Units: 32, Activation: tanh, Optimizer: adam, Loss: binary_crossentropy, Epochs: 10, Batch Size: 64, Accuracy: 0.8181666666666667\n",
      "188/188 [==============================] - 0s 1ms/step\n",
      "Units: 32, Activation: tanh, Optimizer: adam, Loss: binary_crossentropy, Epochs: 20, Batch Size: 32, Accuracy: 0.8216666666666667\n",
      "188/188 [==============================] - 0s 1ms/step\n",
      "Units: 32, Activation: tanh, Optimizer: adam, Loss: binary_crossentropy, Epochs: 20, Batch Size: 64, Accuracy: 0.8251666666666667\n",
      "188/188 [==============================] - 0s 1ms/step\n",
      "Units: 32, Activation: tanh, Optimizer: adam, Loss: binary_crossentropy, Epochs: 50, Batch Size: 32, Accuracy: 0.8181666666666667\n",
      "188/188 [==============================] - 0s 1ms/step\n",
      "Units: 32, Activation: tanh, Optimizer: adam, Loss: binary_crossentropy, Epochs: 50, Batch Size: 64, Accuracy: 0.8245\n",
      "188/188 [==============================] - 1s 4ms/step\n",
      "Units: 32, Activation: tanh, Optimizer: sgd, Loss: binary_crossentropy, Epochs: 10, Batch Size: 32, Accuracy: 0.819\n",
      "188/188 [==============================] - 1s 3ms/step\n",
      "Units: 32, Activation: tanh, Optimizer: sgd, Loss: binary_crossentropy, Epochs: 10, Batch Size: 64, Accuracy: 0.816\n",
      "188/188 [==============================] - 0s 2ms/step\n",
      "Units: 32, Activation: tanh, Optimizer: sgd, Loss: binary_crossentropy, Epochs: 20, Batch Size: 32, Accuracy: 0.821\n",
      "188/188 [==============================] - 0s 2ms/step\n",
      "Units: 32, Activation: tanh, Optimizer: sgd, Loss: binary_crossentropy, Epochs: 20, Batch Size: 64, Accuracy: 0.8188333333333333\n",
      "188/188 [==============================] - 0s 2ms/step\n",
      "Units: 32, Activation: tanh, Optimizer: sgd, Loss: binary_crossentropy, Epochs: 50, Batch Size: 32, Accuracy: 0.8228333333333333\n",
      "188/188 [==============================] - 1s 3ms/step\n",
      "Units: 32, Activation: tanh, Optimizer: sgd, Loss: binary_crossentropy, Epochs: 50, Batch Size: 64, Accuracy: 0.823\n",
      "188/188 [==============================] - 0s 2ms/step\n",
      "Units: 64, Activation: relu, Optimizer: adam, Loss: binary_crossentropy, Epochs: 10, Batch Size: 32, Accuracy: 0.8215\n",
      "188/188 [==============================] - 0s 2ms/step\n",
      "Units: 64, Activation: relu, Optimizer: adam, Loss: binary_crossentropy, Epochs: 10, Batch Size: 64, Accuracy: 0.8218333333333333\n",
      "188/188 [==============================] - 0s 2ms/step\n",
      "Units: 64, Activation: relu, Optimizer: adam, Loss: binary_crossentropy, Epochs: 20, Batch Size: 32, Accuracy: 0.82\n",
      "188/188 [==============================] - 1s 2ms/step\n",
      "Units: 64, Activation: relu, Optimizer: adam, Loss: binary_crossentropy, Epochs: 20, Batch Size: 64, Accuracy: 0.8218333333333333\n",
      "188/188 [==============================] - 0s 2ms/step\n",
      "Units: 64, Activation: relu, Optimizer: adam, Loss: binary_crossentropy, Epochs: 50, Batch Size: 32, Accuracy: 0.821\n",
      "188/188 [==============================] - 0s 2ms/step\n",
      "Units: 64, Activation: relu, Optimizer: adam, Loss: binary_crossentropy, Epochs: 50, Batch Size: 64, Accuracy: 0.8216666666666667\n",
      "169/188 [=========================>....] - ETA: 0s"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[51], line 37\u001b[0m\n\u001b[0;32m     34\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, epochs\u001b[38;5;241m=\u001b[39mepochs, batch_size\u001b[38;5;241m=\u001b[39mbatch_size, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# Evaluate model\u001b[39;00m\n\u001b[1;32m---> 37\u001b[0m y_val_pred \u001b[38;5;241m=\u001b[39m (\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.5\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mint32\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     38\u001b[0m acc \u001b[38;5;241m=\u001b[39m accuracy_score(y_val, y_val_pred)\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnits: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00munits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Activation: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mactivation\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Optimizer: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moptimizer\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Epochs: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Batch Size: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbatch_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00macc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:2554\u001b[0m, in \u001b[0;36mModel.predict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   2552\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39msteps():\n\u001b[0;32m   2553\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_predict_batch_begin(step)\n\u001b[1;32m-> 2554\u001b[0m     tmp_batch_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2555\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   2556\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    822\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    824\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 825\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    827\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    828\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:864\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    861\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    862\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    863\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 864\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    865\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ALLOW_DYNAMIC_VARIABLE_CREATION:\n\u001b[0;32m    866\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    867\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:148\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    146\u001b[0m   (concrete_function,\n\u001b[0;32m    147\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m--> 148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:1349\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs)\u001b[0m\n\u001b[0;32m   1345\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1347\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1348\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1349\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1350\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1351\u001b[0m     args,\n\u001b[0;32m   1352\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1353\u001b[0m     executing_eagerly)\n\u001b[0;32m   1354\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:196\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    195\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 196\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    201\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    202\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mlist\u001b[39m(args))\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1457\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1455\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1457\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1458\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1459\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1460\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1461\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1462\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1463\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1464\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1465\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1466\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1467\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1471\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1472\u001b[0m   )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Standardize your input and split the data into training and validation sets\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "\n",
    "# Hyperparameter settings you want to try\n",
    "n_hidden_units = [32, 64, 128]\n",
    "activations = ['relu', 'tanh']\n",
    "optimizers = ['adam', 'sgd']\n",
    "losses = ['binary_crossentropy']\n",
    "epochs_list = [10, 20, 50]\n",
    "batch_sizes = [32, 64]\n",
    "\n",
    "# To store the best model\n",
    "best_model = None\n",
    "best_accuracy = 0.0\n",
    "\n",
    "# Nested loop to try different hyperparameters\n",
    "for units in n_hidden_units:\n",
    "    for activation in activations:\n",
    "        for optimizer in optimizers:\n",
    "            for loss in losses:\n",
    "                for epochs in epochs_list:\n",
    "                    for batch_size in batch_sizes:\n",
    "                        # Create model\n",
    "                        model = tf.keras.Sequential()\n",
    "                        model.add(tf.keras.layers.Dense(units, activation=activation, input_shape=(X_train.shape[1],)))\n",
    "                        model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "                        # Compile model\n",
    "                        model.compile(loss=loss, optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "                        # Fit model (You can also add validation data here)\n",
    "                        model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, verbose=0)\n",
    "\n",
    "                        # Evaluate model\n",
    "                        y_val_pred = (model.predict(X_val) > 0.5).astype(\"int32\")\n",
    "                        acc = accuracy_score(y_val, y_val_pred)\n",
    "\n",
    "                        print(f\"Units: {units}, Activation: {activation}, Optimizer: {optimizer}, Loss: {loss}, Epochs: {epochs}, Batch Size: {batch_size}, Accuracy: {acc}\")\n",
    "\n",
    "                        # Store the best model\n",
    "                        if acc > best_accuracy:\n",
    "                            best_accuracy = acc\n",
    "                            best_model = model\n",
    "\n",
    "print(\"Best Validation Accuracy: \", best_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a76d046-8998-4bad-802d-43d3ef2e67e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
